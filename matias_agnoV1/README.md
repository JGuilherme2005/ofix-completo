# ğŸš— Matias AI - Assistente Automotivo Inteligente

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/)
[![Agno](https://img.shields.io/badge/Agno-2.0.11-green.svg)](https://agno.dev)
[![Hugging Face](https://img.shields.io/badge/HF-Qwen2.5--7B-orange.svg)](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)
[![Deploy](https://img.shields.io/badge/Deploy-Render-purple.svg)](https://matias-agno-assistant.onrender.com)

**Assistente AI especializado em oficina automotiva com sistema de memÃ³ria persistente e base de conhecimento RAG de 624 documentos tÃ©cnicos.**

---

## ğŸ“‹ VisÃ£o Geral

**Matias** Ã© um agente conversacional avanÃ§ado desenvolvido com **AgentOS (Agno Framework)** que combina:

- ğŸ¤– **LLM Open-Source**: Qwen/Qwen2.5-7B-Instruct (Hugging Face)
- ğŸ§  **MemÃ³ria Persistente**: SQLite com histÃ³rico de conversas por usuÃ¡rio
- ğŸ“š **RAG (Retrieval-Augmented Generation)**: 624 chunks de conhecimento tÃ©cnico
- ğŸ” **Busca Vetorial**: LanceDB Remote com embeddings FastEmbed
- ğŸš€ **Deploy em ProduÃ§Ã£o**: Render.com com auto-scaling

---

## ğŸ¯ Funcionalidades Principais

### 1. **Sistema de MemÃ³ria Contextual**
```python
# O Matias lembra de conversas anteriores
UsuÃ¡rio: "Meu carro Ã© um Gol 2015 1.6 preto, placa ABC-1234"
Matias: "âœ… Entendido! Vou lembrar dessas informaÃ§Ãµes."

# PrÃ³xima conversa (mesmo usuÃ¡rio)
UsuÃ¡rio: "Qual modelo Ã© meu carro?"
Matias: "Seu Volkswagen Gol 2015 1.6, cor preta, placa ABC-1234"
```

**Tecnologia:**
- `SqliteDb` com `enable_user_memories=True`
- Rastreamento por `user_id` e `session_id`
- HistÃ³rico das Ãºltimas 5 conversas (`num_history_runs=5`)

### 2. **Base de Conhecimento RAG**

**624 documentos processados** divididos em 5 categorias:

| Categoria | Documentos | Exemplos |
|-----------|------------|----------|
| ğŸ”§ **TÃ©cnico** | 217 chunks | Manuais de serviÃ§o, cÃ³digos de falha, procedimentos |
| ğŸ’¼ **GestÃ£o** | 197 chunks | OrÃ§amentos, agendamentos, financeiro |
| ğŸ”© **PeÃ§as** | 111 chunks | CatÃ¡logos, fornecedores, estoque |
| ğŸ› ï¸ **ServiÃ§os** | 42 chunks | RevisÃµes, manutenÃ§Ã£o preventiva |
| ğŸ“œ **LegislaÃ§Ã£o** | 57 chunks | Normas CONTRAN, inspeÃ§Ã£o veicular |

**Pipeline RAG:**
1. Query do usuÃ¡rio â†’ Embedding (FastEmbed BAAI/bge-small-en-v1.5)
2. Busca vetorial â†’ LanceDB Remote (`db://ofx-rbf7i6`)
3. Top-3 documentos similares â†’ Contexto para LLM
4. Resposta fundamentada com citaÃ§Ãµes de fonte

**Exemplo:**
```
UsuÃ¡rio: "Quanto custa troca de pastilha de freio?"
Matias busca em: precos_servicos.md
Resposta: "ğŸ’° Pastilhas de freio dianteiras: R$ 180-250 (mÃ£o de obra inclusa)"
```

### 3. **IntegraÃ§Ã£o com Backend OFIX**

**Arquitetura Multi-Agente:**

```mermaid
Frontend (Vercel) â†’ Backend OFIX (Node.js) â†’ Matias Agno (Python)
                         â†“                          â†“
                    PostgreSQL DB            LanceDB Remote + SQLite
```

**Endpoints:**
- `POST /agents/matias/runs` - Criar conversa
- `GET /memories?user_id=X` - Buscar memÃ³rias
- `DELETE /memories?user_id=X` - Limpar histÃ³rico (LGPD)
- `GET /health` - Status do sistema

**Circuit Breaker:** ProteÃ§Ã£o contra rate limits (429) com fallback local.

---

## ğŸ—ï¸ Arquitetura TÃ©cnica

### Stack TecnolÃ³gico

```yaml
Framework: AgentOS (Agno 2.0.11)
LLM: Qwen/Qwen2.5-7B-Instruct (Hugging Face Inference API)
Embeddings: FastEmbed (BAAI/bge-small-en-v1.5-onnx-Q, 384D)
Vector DB: LanceDB Remote (v0.25.3)
Memory: SQLite (tmp/matias_memory.db)
API: FastAPI + Uvicorn
Deploy: Render.com (PORT=10000)
Python: 3.12+
```

### Estrutura do Projeto

```
matias_agnoV1/
â”œâ”€â”€ matias_agno/                    # CÃ³digo principal
â”‚   â”œâ”€â”€ agent_with_memory.py       # ğŸŸ¢ Agente em produÃ§Ã£o (memÃ³ria ativa)
â”‚   â”œâ”€â”€ agent.py                   # ğŸ”´ VersÃ£o sem memÃ³ria (deprecated)
â”‚   â”œâ”€â”€ config.py                  # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ requirements.txt           # DependÃªncias Python
â”‚   â”œâ”€â”€ Dockerfile                 # Container Docker
â”‚   â”œâ”€â”€ render.yaml                # Deploy Render
â”‚   â”‚
â”‚   â”œâ”€â”€ conhecimento_oficina/      # ğŸ“š Base RAG - Categoria 1 (TÃ©cnico)
â”‚   â”‚   â”œâ”€â”€ ar_condicionado.md
â”‚   â”‚   â”œâ”€â”€ sistema_motor.md
â”‚   â”‚   â”œâ”€â”€ precos_servicos.md
â”‚   â”‚   â””â”€â”€ ... (12 arquivos)
â”‚   â”‚
â”‚   â”œâ”€â”€ documentos_md/             # ğŸ“š Base RAG - Categorias 2-5
â”‚   â”‚   â”œâ”€â”€ 1_tecnico/             # Manuais tÃ©cnicos (217 chunks)
â”‚   â”‚   â”œâ”€â”€ 2_gestao/              # GestÃ£o e processos (197 chunks)
â”‚   â”‚   â”œâ”€â”€ 3_pecas/               # CatÃ¡logo de peÃ§as (111 chunks)
â”‚   â”‚   â”œâ”€â”€ 4_servicos/            # Procedimentos (42 chunks)
â”‚   â”‚   â””â”€â”€ 5_legislacao/          # Normas e leis (57 chunks)
â”‚   â”‚
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ tests/                         # ğŸ§ª Testes automatizados
â”‚   â”œâ”€â”€ test_final_completo.py     # Suite com 6 testes
â”‚   â”œâ”€â”€ test_memoria_render_v2.py
â”‚   â””â”€â”€ test_knowledge_detailed.py
â”‚
â”œâ”€â”€ docs/                          # ğŸ“– DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ QUICK_START.md             # Guia de inÃ­cio rÃ¡pido
â”‚   â”œâ”€â”€ GUIA_AGENTOS_AVANCADO.md   # Recursos avanÃ§ados
â”‚   â””â”€â”€ REVIEW_AGNO_ROUTES.md      # AnÃ¡lise do backend
â”‚
â”œâ”€â”€ .env.example                   # Template de variÃ¡veis
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                      # ğŸ‘ˆ Este arquivo
```

### Fluxo de ExecuÃ§Ã£o

```python
# 1. UsuÃ¡rio envia mensagem
POST /agents/matias/runs
{
  "message": "Qual o torque da roda do Gol?",
  "user_id": "user_123",
  "session_id": "session_456"
}

# 2. Matias classifica a intenÃ§Ã£o
MessageClassifier â†’ "CONSULTA_TECNICA" â†’ Usar tool buscar_conhecimento()

# 3. RAG Pipeline
query = "torque roda Gol"
embedding = FastEmbedEmbedder.get_embedding(query)  # 384 dimensÃµes
results = lancedb.search(embedding).limit(3)        # Top-3 similares

# 4. LLM gera resposta com contexto
HuggingFace(Qwen2.5-7B).generate(
  system_prompt=INSTRUCTIONS,
  user_message=query,
  context=results  # Documentos recuperados do RAG
)

# 5. Salvar memÃ³ria
SqliteDb.save_memory(
  user_id="user_123",
  content="UsuÃ¡rio perguntou sobre torque de rodas do Gol"
)

# 6. Retornar resposta
{
  "response": "ğŸ”§ Torque de aperto: 120 Nm (fonte: tabela_torques.txt)",
  "session_id": "session_456",
  "memory_updated": true
}
```

---

## ğŸš€ InstalaÃ§Ã£o e Uso

### PrÃ©-requisitos

```bash
# Python 3.12+
python --version

# Git
git --version
```

### 1. Clonar RepositÃ³rio

```bash
git clone https://github.com/PedroVictor26/matias_agnoV1.git
cd matias_agnoV1
```

### 2. Criar Ambiente Virtual

```bash
# Windows PowerShell
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Instalar DependÃªncias

```bash
cd matias_agno
pip install -r requirements.txt
```

### 4. Configurar VariÃ¡veis de Ambiente

Crie `.env` na raiz de `matias_agno/`:

```bash
# LLM (Hugging Face)
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Vector Database (LanceDB Remote)
LANCEDB_API_KEY=sk_xxxxxxxxxxxxxxxxxxxxxxxxxx
LANCEDB_URI=db://ofx-rbf7i6

# Servidor (Render usa PORT=10000)
PORT=8001

# Debug (opcional)
DEBUG=false
```

### 5. Testar Localmente

```bash
# Executar agente
python agent_with_memory.py

# Em outro terminal, testar endpoint
curl http://localhost:8001/health
```

### 6. Executar Testes

```bash
# Voltar para raiz do projeto
cd ..

# Teste completo (6 cenÃ¡rios)
python test_final_completo.py

# Resultado esperado:
# âœ… 1/6 Health Check: PASS
# âœ… 2/6 Agent Config: PASS (Memory active)
# âœ… 3/6 Create Memory: PASS
# âœ… 4/6 Verify Memory: PASS
# âœ… 5/6 Knowledge Base: PASS (805 tokens)
# âœ… 6/6 Context Maintenance: PASS
```

---

## ğŸŒ Deploy em ProduÃ§Ã£o

### Render.com (ConfiguraÃ§Ã£o Atual)

**VariÃ¡veis de Ambiente no Render:**

```bash
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
LANCEDB_API_KEY=sk_xxxxxxxxxxxxxxxxxxxxxxxxxx
LANCEDB_URI=db://ofx-rbf7i6
PORT=10000  # Render exige porta 10000
PYTHON_VERSION=3.12.0
```

**Build Command:**
```bash
pip install -r requirements.txt
```

**Start Command:**
```bash
python agent_with_memory.py
```

**URL de ProduÃ§Ã£o:**
```
https://matias-agno-assistant.onrender.com
```

### Docker (Alternativa)

```bash
# Build
docker build -t matias-agno .

# Run
docker run -p 8001:8001 --env-file .env matias-agno
```

---

## ğŸ“Š MÃ©tricas de Performance

### Testes de ProduÃ§Ã£o (17/11/2025)

| MÃ©trica | Valor | Status |
|---------|-------|--------|
| Taxa de Sucesso | 100% (6/6 testes) | âœ… |
| Recall de MemÃ³ria | 100% | âœ… |
| LatÃªncia MÃ©dia (RAG) | 3-5s | âš ï¸ LanceDB Remote |
| Tokens por Resposta | 700-900 | âœ… |
| Uptime (Render) | 99.2% | âœ… |
| Cold Start | ~50s (primeira req) | âš ï¸ Free Tier |

### Base de Conhecimento

```
Total: 624 chunks processados
â”œâ”€â”€ 1_tecnico/      217 chunks (34.8%)
â”œâ”€â”€ 2_gestao/       197 chunks (31.6%)
â”œâ”€â”€ 3_pecas/        111 chunks (17.8%)
â”œâ”€â”€ 4_servicos/      42 chunks (6.7%)
â””â”€â”€ 5_legislacao/    57 chunks (9.1%)

Fontes: 65 arquivos originais (PDF, DOCX, TXT)
ConversÃ£o: MarkItDown (Microsoft) â†’ 100% sucesso
Embeddings: BAAI/bge-small-en-v1.5 (384 dimensÃµes)
Storage: LanceDB Remote (us-east-1)
```

---

## ğŸ§ª Exemplos de Uso

### Exemplo 1: MemÃ³ria Contextual

```python
# Conversa 1
User: "Meu carro estÃ¡ fazendo um barulho no freio"
Matias: "Que tipo de barulho vocÃª estÃ¡ ouvindo? Chiado, rangido ou batida?"

User: "Um chiado quando freio"
Matias: "Chiado no freio geralmente indica pastilhas gastas ou disco 
        empenado. Qual o modelo do seu carro?"

User: "Ã‰ um Gol 2015"
Matias: "âœ… Vou lembrar: Gol 2015 com chiado no freio."

# Conversa 2 (prÃ³ximo dia, mesmo usuÃ¡rio)
User: "Quanto custa consertar o problema que te falei?"
Matias: "VocÃª mencionou chiado no freio do seu Gol 2015. 
        ğŸ’° Troca de pastilhas: R$ 180-250 (dianteiras)
        ğŸ”§ RetÃ­fica de disco: R$ 120-180 (por disco)"
```

### Exemplo 2: Busca RAG com CitaÃ§Ã£o

```python
User: "Qual o torque de aperto das rodas do Civic?"
Matias: [buscar_conhecimento("torque rodas Civic")]

# RAG encontra em tabela_torques.txt:
# "Honda Civic 2020-2024: 108 Nm (11 kgfm)"

Matias: "ğŸ”§ **Torque de Aperto - Honda Civic**
        
        ğŸ“Š EspecificaÃ§Ã£o: 108 Nm (11 kgfm)
        âš ï¸ Use torquÃ­metro calibrado
        ğŸ”„ Aperto em cruz (padrÃ£o estrela)
        
        ğŸ“ Fonte: tabela_torques.txt"
```

### Exemplo 3: IntegraÃ§Ã£o com Backend

```javascript
// Frontend envia para Backend OFIX
fetch('/api/agno/chat', {
  method: 'POST',
  body: JSON.stringify({
    message: "Agendar revisÃ£o",
    user_id: "user_27ff6aaf",
    session_id: "session_1763032167330"
  })
});

// Backend classifica e roteia
if (MessageClassifier.classify(message) === 'AGENDAMENTO') {
  // Processa localmente (rÃ¡pido)
  return AgendamentoLocal.processar(message);
} else {
  // Envia para Matias Agno (inteligente)
  return fetch('https://matias-agno-assistant.onrender.com/agents/matias/runs', {
    method: 'POST',
    body: formData
  });
}
```

---

## ğŸ› ï¸ Roadmap

### âœ… ConcluÃ­do (Novembro 2025)
- [x] Sistema de memÃ³ria persistente (SQLite)
- [x] Base de conhecimento RAG (624 docs)
- [x] Deploy em produÃ§Ã£o (Render)
- [x] IntegraÃ§Ã£o com backend OFIX
- [x] Testes automatizados (6/6 passing)
- [x] Circuit breaker para rate limits

### ğŸš§ Em Desenvolvimento
- [ ] Cache de respostas (reduzir custos API)
- [ ] Modelo local fallback (Ollama)
- [ ] MÃ©tricas Prometheus/Grafana
- [ ] RefatoraÃ§Ã£o backend (remover cÃ³digo duplicado)

### ğŸ“‹ Planejado (Dezembro 2025)
- [ ] UI de gerenciamento de memÃ³rias
- [ ] Export de conversas (CSV/JSON)
- [ ] Multi-lÃ­ngua (EN, ES)
- [ ] IntegraÃ§Ã£o WhatsApp Business

---

## ğŸ¤ Contribuindo

### Reportar Bugs

Abra uma issue em: https://github.com/PedroVictor26/matias_agnoV1/issues

**Template:**
```markdown
**DescriÃ§Ã£o:** [Descreva o bug]
**ReproduÃ§Ã£o:** [Passos para reproduzir]
**Esperado:** [Comportamento esperado]
**Logs:** [Cole logs relevantes]
**Ambiente:** [OS, Python version, etc]
```

### Pull Requests

1. Fork o repositÃ³rio
2. Crie branch: `git checkout -b feature/nova-funcionalidade`
3. Commit: `git commit -m 'feat: adiciona X'`
4. Push: `git push origin feature/nova-funcionalidade`
5. Abra PR com descriÃ§Ã£o detalhada

---

## ğŸ“„ LicenÃ§a

**Propriedade Privada** - Â© 2025 OFIX  
Uso comercial restrito. Entre em contato para licenciamento.

---

## ğŸ‘¥ Autores

**Desenvolvedor Principal:** Pedro Victor  
**GitHub:** [@PedroVictor26](https://github.com/PedroVictor26)  
**Email:** [contato em desenvolvimento]

**Agradecimentos:**
- [Agno Framework](https://agno.dev) - Framework de agentes
- [Hugging Face](https://huggingface.co) - Modelos LLM
- [LanceDB](https://lancedb.com) - Vector database
- [MarkItDown](https://github.com/microsoft/markitdown) - ConversÃ£o de documentos

---

## ğŸ”— Links Ãšteis

- ğŸ“š [DocumentaÃ§Ã£o Agno](https://docs.agno.dev)
- ğŸ¤– [Qwen2.5-7B Model Card](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)
- ğŸ” [LanceDB Docs](https://lancedb.github.io/lancedb/)
- ğŸš€ [Deploy em Render](https://render.com/docs)
- ğŸ“– [QUICK_START.md](./QUICK_START.md) - Guia de inÃ­cio rÃ¡pido
- ğŸ”§ [GUIA_AGENTOS_AVANCADO.md](./GUIA_AGENTOS_AVANCADO.md) - Recursos avanÃ§ados

---

## ğŸ“ Suporte

**Issues GitHub:** https://github.com/PedroVictor26/matias_agnoV1/issues  
**Status do Sistema:** https://matias-agno-assistant.onrender.com/health  
**DocumentaÃ§Ã£o:** [Wiki do Projeto](https://github.com/PedroVictor26/matias_agnoV1/wiki)

---

<div align="center">

**â­ Se este projeto te ajudou, considere dar uma estrela! â­**

[![GitHub stars](https://img.shields.io/github/stars/PedroVictor26/matias_agnoV1?style=social)](https://github.com/PedroVictor26/matias_agnoV1)

Feito com â¤ï¸ e â˜• por [Pedro Victor](https://github.com/PedroVictor26)

</div>
